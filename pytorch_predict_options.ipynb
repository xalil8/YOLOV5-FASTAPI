{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halil\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Request, Form, File, UploadFile\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import base64\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\halil/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-10-26 Python-3.8.10 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "xalil_model = torch.hub.load(\"ultralytics/yolov5\",\"custom\",path=\"/Users/halil/Desktop/gity/map92.pt\",force_reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = cv2.imread(\"images/logo_det.png\")\n",
    "rgb = cv2.cvtColor(img_batch, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#results = xalil_model(img_batch, size = 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"asdas\",pred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_json(results, model):\n",
    "    ''' Converts yolo model output to json (list of list of dicts)'''\n",
    "    return [\n",
    "                [\n",
    "                    {\n",
    "                    \"class\": int(pred[5]),\n",
    "                    \"class_name\": model.model.names[int(pred[5])],\n",
    "                    \"bbox\": [int(x) for x in pred[:4].tolist()], #convert bbox results to int from float\n",
    "                    \"confidence\": float(pred[4]),\n",
    "                    }\n",
    "                for pred in result\n",
    "                ]\n",
    "            for result in results.xyxy\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_box(x, im, color=(128, 128, 128), label=None, line_thickness=3):\n",
    "    # Directly copied from: https://github.com/ultralytics/yolov5/blob/cd540d8625bba8a05329ede3522046ee53eb349d/utils/plots.py\n",
    "    # Plots one bounding box on image 'im' using OpenCV\n",
    "    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n",
    "    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "def base64EncodeImage(img):\n",
    "    ''' Takes an input image and returns a base64 encoded string representation of that image (jpg format)'''\n",
    "    _, im_arr = cv2.imencode('.jpg', img)\n",
    "    im_b64 = base64.b64encode(im_arr.tobytes()).decode('utf-8')\n",
    "    return im_b64\n",
    "colors = [tuple([random.randint(0, 255) for _ in range(3)]) for _ in range(100)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xalil_model.conf = 0.5\n",
    "xalil_model.classes = None\n",
    "\n",
    "\n",
    "predictions = xalil_model(rgb,size=640)\n",
    "json = results_to_json(predictions,xalil_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.97071)\n",
      "tensor(0.96864)\n",
      "tensor(0.96447)\n",
      "tensor(0.96063)\n",
      "tensor(0.96057)\n",
      "tensor(0.95985)\n",
      "tensor(0.95580)\n",
      "tensor(0.94003)\n",
      "tensor(0.90477)\n",
      "tensor(0.86653)\n",
      "tensor(0.83399)\n",
      "tensor(0.77290)\n",
      "tensor(0.76663)\n",
      "tensor(0.69803)\n",
      "tensor(0.69729)\n",
      "tensor(0.67905)\n",
      "tensor(0.64835)\n",
      "tensor(0.63204)\n",
      "tensor(0.52999)\n",
      "tensor(0.51663)\n"
     ]
    }
   ],
   "source": [
    "for  results in predictions.xyxy:\n",
    "    for result in results:\n",
    "        print(result[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 0, 'class_name': 'apple', 'bbox': [827, 397, 901, 485], 'confidence': 0.9707061052322388}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [373, 355, 513, 532], 'confidence': 0.9686378836631775}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [291, 610, 410, 754], 'confidence': 0.9644722938537598}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [548, 606, 674, 769], 'confidence': 0.9606329798698425}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [20, 354, 166, 535], 'confidence': 0.9605681896209717}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [623, 415, 680, 479], 'confidence': 0.959848940372467}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [230, 403, 300, 489], 'confidence': 0.9558010101318359}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [1250, 651, 1301, 714], 'confidence': 0.9400272369384766}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [503, 842, 549, 891], 'confidence': 0.904768705368042}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [803, 292, 830, 321], 'confidence': 0.8665332198143005}\n",
      "{'class': 2, 'class_name': 'facebook', 'bbox': [170, 843, 209, 884], 'confidence': 0.8339933753013611}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [675, 844, 714, 885], 'confidence': 0.7728956341743469}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [1230, 836, 1268, 888], 'confidence': 0.7666271924972534}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [391, 841, 438, 887], 'confidence': 0.6980328559875488}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [728, 844, 771, 885], 'confidence': 0.6972918510437012}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [807, 843, 854, 891], 'confidence': 0.6790528297424316}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [447, 840, 494, 883], 'confidence': 0.648351788520813}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [621, 846, 662, 886], 'confidence': 0.6320352554321289}\n",
      "{'class': 0, 'class_name': 'apple', 'bbox': [1028, 428, 1044, 450], 'confidence': 0.529987096786499}\n",
      "{'class': 3, 'class_name': 'google', 'bbox': [1175, 42, 1191, 55], 'confidence': 0.5166311860084534}\n"
     ]
    }
   ],
   "source": [
    "for i in json[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str_list = []\n",
    "#plot bboxes on the image\n",
    "for img, bbox_list in zip(img_batch, json):\n",
    "    for bbox in bbox_list:\n",
    "        label = f'{bbox[\"class_name\"]} {bbox[\"confidence\"]:.2f}'\n",
    "        plot_one_box(bbox['bbox'], img, label=label, \n",
    "                color=colors[int(bbox['class'])], line_thickness=3)\n",
    "\n",
    "    img_str_list.append(base64EncodeImage(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['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']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
